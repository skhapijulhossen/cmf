{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WkHi07Xw_eln",
        "nUN5kiwY-6bq",
        "StKP9Z-dECqG",
        "fKRaXcx6UGLy",
        "aBwc1-fCE_Ti"
      ],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#installs"
      ],
      "metadata": {
        "id": "WkHi07Xw_eln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install fastapi kaleido python-multipart uvicorn numpy==1.24.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "id": "rs3AMBFP_eFo",
        "outputId": "0732a694-9983-4f73-e456-be7a728ca87a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/92.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m92.2/92.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.24.1\n",
            "  Downloading numpy-1.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.7.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (1.10.13)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.8.0 (from fastapi)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.1.3)\n",
            "Installing collected packages: kaleido, typing-extensions, python-multipart, numpy, h11, uvicorn, starlette, fastapi\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fastapi-0.104.1 h11-0.14.0 kaleido-0.2.1 numpy-1.24.1 python-multipart-0.0.6 starlette-0.27.0 typing-extensions-4.8.0 uvicorn-0.24.0.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rs5-iQMY_eUP",
        "outputId": "56e24017-8ae9-4b4f-8ce6-0f37f844c2b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (3.3.2)\n",
            "Collecting colorama==0.4.6 (from -r requirements.txt (line 4))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: contourpy==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: filelock==3.13.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.13.1)\n",
            "Requirement already satisfied: fonttools==4.44.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.44.0)\n",
            "Collecting fsspec==2023.10.0 (from -r requirements.txt (line 9))\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna==3.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (3.4)\n",
            "Collecting imageio==2.32.0 (from -r requirements.txt (line 11))\n",
            "  Downloading imageio-2.32.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.3/313.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imgaug==0.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.4.0)\n",
            "Requirement already satisfied: Jinja2==3.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (3.1.2)\n",
            "Requirement already satisfied: joblib==1.3.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (1.3.2)\n",
            "Requirement already satisfied: kiwisolver==1.4.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (1.4.5)\n",
            "Requirement already satisfied: lazy_loader==0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.3)\n",
            "Requirement already satisfied: MarkupSafe==2.1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.1.3)\n",
            "Collecting matplotlib==3.8.1 (from -r requirements.txt (line 18))\n",
            "  Downloading matplotlib-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (1.3.0)\n",
            "Requirement already satisfied: networkx==3.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (3.2.1)\n",
            "Collecting opencv-python==4.8.1.78 (from -r requirements.txt (line 21))\n",
            "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless==4.8.1.78 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (4.8.1.78)\n",
            "Requirement already satisfied: packaging==23.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (23.2)\n",
            "Collecting Pillow==10.0.1 (from -r requirements.txt (line 24))\n",
            "  Downloading Pillow-10.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing==3.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (2.8.2)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (6.0.1)\n",
            "Requirement already satisfied: qudida==0.0.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.0.4)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (2.31.0)\n",
            "Collecting scikit-image==0.22.0 (from -r requirements.txt (line 30))\n",
            "  Downloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.3.2 (from -r requirements.txt (line 31))\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m127.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy==1.11.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (1.11.3)\n",
            "Requirement already satisfied: shapely==2.0.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (2.0.2)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (1.16.0)\n",
            "Requirement already satisfied: sympy==1.12 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (1.12)\n",
            "Requirement already satisfied: threadpoolctl==3.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 36)) (3.2.0)\n",
            "Requirement already satisfied: tifffile==2023.9.26 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 37)) (2023.9.26)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 38)) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision==0.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 39)) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 40)) (4.66.1)\n",
            "Requirement already satisfied: typing_extensions==4.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 41)) (4.8.0)\n",
            "Requirement already satisfied: urllib3==2.0.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->-r requirements.txt (line 1)) (1.24.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 38)) (2.1.0)\n",
            "Installing collected packages: Pillow, opencv-python, fsspec, colorama, scikit-learn, matplotlib, imageio, scikit-image\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.8.0.76\n",
            "    Uninstalling opencv-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-python-4.8.0.76\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.6.0\n",
            "    Uninstalling fsspec-2023.6.0:\n",
            "      Successfully uninstalled fsspec-2023.6.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.31.6\n",
            "    Uninstalling imageio-2.31.6:\n",
            "      Successfully uninstalled imageio-2.31.6\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.19.3\n",
            "    Uninstalling scikit-image-0.19.3:\n",
            "      Successfully uninstalled scikit-image-0.19.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.0.1 colorama-0.4.6 fsspec-2023.10.0 imageio-2.32.0 matplotlib-3.8.1 opencv-python-4.8.1.78 scikit-image-0.22.0 scikit-learn-1.3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "cv2",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#imports"
      ],
      "metadata": {
        "id": "nUN5kiwY-6bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import albumentations as alb\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "t5TqiqCF-2_G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "CH0U1uQm-28P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing"
      ],
      "metadata": {
        "id": "D-li5cON-22H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Configuration"
      ],
      "metadata": {
        "id": "T7T_Y6VJ-yUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
        "cores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3lmBit6AmvF",
        "outputId": "70ab171a-2ee6-4dd6-c440-8baaabcd690c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "2xJ0N1ZL-CBV"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "TRAIN_DIR = \"/content/drive/MyDrive/CopyMoveForgeryDetection/fold0\"\n",
        "VAL_DIR = \"/content/drive/MyDrive/CopyMoveForgeryDetection/validate\"\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 1e-5\n",
        "LAMBDA_IDENTITY = 0.0\n",
        "LAMBDA_CYCLE = 10\n",
        "NUM_WORKERS = 2\n",
        "NUM_EPOCHS = 10\n",
        "LOAD_MODEL = False\n",
        "SAVE_MODEL = True\n",
        "CHECKPOINT_GEN_H = \"genX.pth.tar\"\n",
        "CHECKPOINT_GEN_Z = \"genY.pth.tar\"\n",
        "CHECKPOINT_CRITIC_H = \"criticX.pth.tar\"\n",
        "CHECKPOINT_CRITIC_Z = \"criticY.pth.tar\"\n",
        "\n",
        "\n",
        "### Transformations before feeding\n",
        "transforms = alb.Compose(\n",
        "    [\n",
        "        alb.Resize(width=512, height=512),\n",
        "        alb.HorizontalFlip(p=0.5),\n",
        "        alb.Normalize(mean=[0.5, 0.5, 0.5], std=[\n",
        "                      0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        "    additional_targets={\"image0\": \"image\"}, is_check_shapes=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wAHBUhoJECAa"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mvc2wqj-EB-X"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cwVqP7zIEB8O"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Pre-process"
      ],
      "metadata": {
        "id": "StKP9Z-dECqG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hzogjo4BEMbD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HorseZebraDataset(Dataset):\n",
        "    def __init__(self, root_y, root_x, transform=None):\n",
        "        self.root_y = root_y\n",
        "        self.root_x = root_x\n",
        "        self.transform = transform\n",
        "\n",
        "        self.y_images = os.listdir(root_y)\n",
        "        self.x_images = os.listdir(root_x)\n",
        "        self.length_dataset = max(len(self.y_images), len(self.x_images)) # 1000, 1500\n",
        "        self.y_len = len(self.y_images)\n",
        "        self.x_len = len(self.x_images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        y_img = self.y_images[index % self.y_len]\n",
        "        x_img = self.x_images[index % self.x_len]\n",
        "\n",
        "        zebra_path = os.path.join(self.root_y, y_img)\n",
        "        horse_path = os.path.join(self.root_x, x_img)\n",
        "\n",
        "        y_img = np.array(Image.open(zebra_path).convert(\"RGB\"))\n",
        "        x_img = np.array(Image.open(horse_path).convert(\"RGB\"))\n",
        "\n",
        "        if self.transform:\n",
        "            augmentations = self.transform(image=y_img, image0=x_img)\n",
        "            y_img = augmentations[\"image\"]\n",
        "            x_img = augmentations[\"image0\"]\n",
        "\n",
        "        return y_img, x_img\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a7NMH32HEB6a"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QX8UtXVhEB4C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P0LGwI1xEW8B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i3VUYwGNEW5S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture\n",
        "<img src=\"https://imgs.search.brave.com/ycwQQQ4PY2s_Ai8M_pGgFYCJckpOr46RCAz7A8vBWqo/rs:fit:860:0:0/g:ce/aHR0cHM6Ly93d3cu/c2NhbGVyLmNvbS90/b3BpY3MvaW1hZ2Vz/L2FyY2hpdGVjdHVy/ZS1pbi1jeWNsZWdh/bi53ZWJw\">"
      ],
      "metadata": {
        "id": "8NWc1bpJT8sC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator\n",
        "<img src=\"https://imgs.search.brave.com/5BWq-72d0cEZSySvkUyo5IcA0OmdyT0ijrMjXmx7aJ0/rs:fit:860:0:0/g:ce/aHR0cHM6Ly93d3cu/c2NhbGVyLmNvbS90/b3BpY3MvaW1hZ2Vz/L2dlbmVyYXRvci1h/cmNoaXRlY3R1cmUt/aW4tY3ljbGVnYW4u/d2VicA\">"
      ],
      "metadata": {
        "id": "fKRaXcx6UGLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs) if down else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True) if use_act else nn.Identity(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "###\n",
        "class DoubleConv(nn. Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super (DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "        nn.Conv2d (in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "        nn. BatchNorm2d (out_channels),\n",
        "        nn. ReLU(inplace=True),\n",
        "        nn. Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "        nn. BatchNorm2d (out_channels),\n",
        "        nn. ReLU(inplace=True),\n",
        "        )\n",
        "    def forward (self, x):\n",
        "        return self.conv(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "KQbWxZVYEW0t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "    \"\"\"\n",
        "    UNET Module\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=3, out_channels=3, features=[64, 128, 256, 512]):\n",
        "        super (UNET, self).__init__()\n",
        "        self.upsample_steps = nn.ModuleList()\n",
        "        self.downsample_steps = nn.ModuleList()\n",
        "        self.pool = nn. MaxPool2d (kernel_size=2, stride=2)\n",
        "\n",
        "        # DownsamplingBlock of UNET\n",
        "        for feature in features:\n",
        "            self.downsample_steps.append (DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # ##\n",
        "        self.bottleneck = DoubleConv(features[-1], features [-1]*2)\n",
        "\n",
        "        # UpsamplingBlock of UNET\n",
        "        for feature in reversed(features):\n",
        "            self.upsample_steps.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))\n",
        "\n",
        "            self.upsample_steps.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        # downsample\n",
        "        for downsample in self.downsample_steps:\n",
        "            x = downsample(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        # bottleneck - before upsample\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        # upsample\n",
        "        for index in range(0, len(self.upsample_steps), 2):\n",
        "            x = self.upsample_steps[index](x)\n",
        "            skip_connection = skip_connections[index//2]\n",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "            x = self.upsample_steps[index+1](concat_skip)\n",
        "        return self.final_conv(x)"
      ],
      "metadata": {
        "id": "CnUQCl91vNWK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-GElnHO6vNRi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, img_channels, num_features=64):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                img_channels,\n",
        "                num_features,\n",
        "                kernel_size=7,\n",
        "                stride=1,\n",
        "                padding=3,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.InstanceNorm2d(num_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.down_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(\n",
        "                    num_features, num_features * 2, kernel_size=3, stride=2, padding=1\n",
        "                ),\n",
        "                ConvBlock(\n",
        "                    num_features * 2,\n",
        "                    num_features * 4,\n",
        "                    kernel_size=3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "\n",
        "        # UNET START\n",
        "        self.UNET_block = UNET(in_channels=36, out_channels=256, features=[64, 128, 256])\n",
        "\n",
        "\n",
        "        # UNET END\n",
        "\n",
        "        self.up_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(\n",
        "                    num_features * 4,\n",
        "                    num_features * 2,\n",
        "                    down=False,\n",
        "                    kernel_size=3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                    output_padding=1,\n",
        "                ),\n",
        "                ConvBlock(\n",
        "                    num_features * 2,\n",
        "                    num_features * 1,\n",
        "                    down=False,\n",
        "                    kernel_size=3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                    output_padding=1,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.last = nn.Conv2d(\n",
        "            num_features * 1,\n",
        "            img_channels,\n",
        "            kernel_size=7,\n",
        "            stride=1,\n",
        "            padding=3,\n",
        "            padding_mode=\"reflect\",\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(x.shape)\n",
        "        x = self.initial(x)\n",
        "        for layer in self.down_blocks:\n",
        "            x = layer(x)\n",
        "            print(x.shape)\n",
        "        x = self.UNET_block(x)\n",
        "        print(x.shape)\n",
        "        for layer in self.up_blocks:\n",
        "            x = layer(x)\n",
        "            print(x.shape)\n",
        "        return torch.tanh(self.last(x))"
      ],
      "metadata": {
        "id": "sWKGZbMn3lW-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    img_channels = 3\n",
        "    img_size = 256\n",
        "    x = torch.randn((2, img_channels, img_size, img_size))\n",
        "    gen = UNET(img_channels)\n",
        "    print(gen(x).shape)"
      ],
      "metadata": {
        "id": "9ALpyk8s3qOA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hvRy6W4EWyY",
        "outputId": "dc95fb12-9cdb-4c9b-d137-316a0685952f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator\n",
        "\n",
        "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200605220731/Discriminator.jpg\">"
      ],
      "metadata": {
        "id": "aBwc1-fCE_Ti"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JHp_p7qfE-Oc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic building block for the discriminator called Block.\n",
        "    This block consists of a convolutional layer with instance normalization and leaky ReLU activation.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                4,\n",
        "                stride,\n",
        "                1,\n",
        "                bias=True,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "    ### Will perform Forward Prop\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Intregated Discriminator Network\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                features[0],\n",
        "                kernel_size=4,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        ### Layers for Discriminator\n",
        "        layers = []\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            layers.append(\n",
        "                Block(in_channels, feature,\n",
        "                      stride=1 if feature == features[-1] else 2)\n",
        "            )\n",
        "            in_channels = feature\n",
        "\n",
        "        ### Layer before output\n",
        "        layers.append(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                1,\n",
        "                kernel_size=4,\n",
        "                stride=1,\n",
        "                padding=1,\n",
        "                padding_mode=\"reflect\",\n",
        "            )\n",
        "        )\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        return torch.sigmoid(self.model(x))\n"
      ],
      "metadata": {
        "id": "vS955HchE-MP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Test Discriminator\n",
        "def test():\n",
        "    x = torch.randn((5, 3, 256, 256))\n",
        "    model = Discriminator(in_channels=3)\n",
        "    preds = model(x)\n",
        "    print(preds.shape)"
      ],
      "metadata": {
        "id": "NucsF7-x8ZKw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzq_arSAE-Ie",
        "outputId": "84b81121-698e-4ac7-f778-90b3002e07fd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 1, 30, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilities"
      ],
      "metadata": {
        "id": "wxf0aQWWX86C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, numpy as np\n",
        "import copy"
      ],
      "metadata": {
        "id": "M7zsgvOSYDqM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # and it will lead to many hours of debugging \\:\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "xAYPmHgDX8lD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZTd5DP6fX8hB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sxlsvIjfX8em"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6U5yiu7zX8b_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LCL70-p-X8Y6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e-kGJJOWXxuF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n4v6R1SJXxsB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "970pCKQaXyfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "fO2JO8Q8Xxp2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler):\n",
        "    H_reals = 0\n",
        "    H_fakes = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (zebra, horse) in enumerate(loop):\n",
        "        zebra = zebra.to(DEVICE)\n",
        "        horse = horse.to(DEVICE)\n",
        "\n",
        "        # Train Discriminators H and Z\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_horse = gen_H(zebra)\n",
        "            D_H_real = disc_H(horse)\n",
        "            D_H_fake = disc_H(fake_horse.detach())\n",
        "            H_reals += D_H_real.mean().item()\n",
        "            H_fakes += D_H_fake.mean().item()\n",
        "            D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n",
        "            D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n",
        "            D_H_loss = D_H_real_loss + D_H_fake_loss\n",
        "\n",
        "            fake_zebra = gen_Z(horse)\n",
        "            D_Z_real = disc_Z(zebra)\n",
        "            D_Z_fake = disc_Z(fake_zebra.detach())\n",
        "            D_Z_real_loss = mse(D_Z_real, torch.ones_like(D_Z_real))\n",
        "            D_Z_fake_loss = mse(D_Z_fake, torch.zeros_like(D_Z_fake))\n",
        "            D_Z_loss = D_Z_real_loss + D_Z_fake_loss\n",
        "\n",
        "            # put it togethor\n",
        "            D_loss = (D_H_loss + D_Z_loss) / 2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train Generators H and Z\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # adversarial loss for both generators\n",
        "            D_H_fake = disc_H(fake_horse)\n",
        "            D_Z_fake = disc_Z(fake_zebra)\n",
        "            loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n",
        "            loss_G_Z = mse(D_Z_fake, torch.ones_like(D_Z_fake))\n",
        "\n",
        "            # cycle loss\n",
        "            cycle_zebra = gen_Z(fake_horse)\n",
        "            cycle_horse = gen_H(fake_zebra)\n",
        "            cycle_zebra_loss = l1(zebra, cycle_zebra)\n",
        "            cycle_horse_loss = l1(horse, cycle_horse)\n",
        "\n",
        "            # identity loss (remove these for efficiency if you set lambda_identity=0)\n",
        "            identity_zebra = gen_Z(zebra)\n",
        "            identity_horse = gen_H(horse)\n",
        "            identity_zebra_loss = l1(zebra, identity_zebra)\n",
        "            identity_horse_loss = l1(horse, identity_horse)\n",
        "\n",
        "            # add all togethor\n",
        "            G_loss = (\n",
        "                loss_G_Z\n",
        "                + loss_G_H\n",
        "                + cycle_zebra_loss * LAMBDA_CYCLE\n",
        "                + cycle_horse_loss * LAMBDA_CYCLE\n",
        "                + identity_horse_loss * LAMBDA_IDENTITY\n",
        "                + identity_zebra_loss * LAMBDA_IDENTITY\n",
        "            )\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        if idx % 200 == 0:\n",
        "            save_image(fake_horse * 0.5 + 0.5, f\"horse_{idx}.png\")\n",
        "            save_image(fake_zebra * 0.5 + 0.5, f\"zebra_{idx}.png\")\n",
        "\n",
        "        loop.set_postfix(H_real=H_reals / (idx + 1),\n",
        "                         H_fake=H_fakes / (idx + 1))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ky_vO2GZXxny"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    disc_H = Discriminator(in_channels=3).to(DEVICE)\n",
        "    disc_Z = Discriminator(in_channels=3).to(DEVICE)\n",
        "    gen_Z = UNET(in_channels=3).to(DEVICE)\n",
        "    gen_H = UNET(in_channels=3).to(DEVICE)\n",
        "    opt_disc = optim.Adam(\n",
        "        list(disc_H.parameters()) + list(disc_Z.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    opt_gen = optim.Adam(\n",
        "        list(gen_Z.parameters()) + list(gen_H.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_H,\n",
        "            gen_H,\n",
        "            opt_gen,\n",
        "            LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_Z,\n",
        "            gen_Z,\n",
        "            opt_gen,\n",
        "            LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC_H,\n",
        "            disc_H,\n",
        "            opt_disc,\n",
        "            LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC_Z,\n",
        "            disc_Z,\n",
        "            opt_disc,\n",
        "            LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "    dataset = HorseZebraDataset(\n",
        "        root_x=TRAIN_DIR + \"/forged\",\n",
        "        root_y=TRAIN_DIR + \"/mask\",\n",
        "        transform=transforms,\n",
        "    )\n",
        "    val_dataset = HorseZebraDataset(\n",
        "        root_x=VAL_DIR + \"/forged\",\n",
        "        root_y=VAL_DIR + \"/mask\",\n",
        "        transform=transforms,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    g_scaler = torch.cuda.amp.GradScaler(enabled=False)\n",
        "    d_scaler = torch.cuda.amp.GradScaler(enabled=False)\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_fn(disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler)\n",
        "\n",
        "        if SAVE_MODEL:\n",
        "            save_checkpoint(gen_H, opt_gen, filename=CHECKPOINT_GEN_H)\n",
        "            save_checkpoint(gen_Z, opt_gen, filename=CHECKPOINT_GEN_Z)\n",
        "            save_checkpoint(disc_H, opt_disc,\n",
        "                            filename=CHECKPOINT_CRITIC_H)\n",
        "            save_checkpoint(disc_Z, opt_disc,\n",
        "                            filename=CHECKPOINT_CRITIC_Z)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CMMRwTSTXxlg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3Kl8e-yE-Gg",
        "outputId": "f941c491-200a-4638-b345-1bc1c323c2e2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [01:33<00:00,  1.60it/s, H_fake=0.424, H_real=0.74]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [01:33<00:00,  1.60it/s, H_fake=0.331, H_real=0.845]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [01:33<00:00,  1.60it/s, H_fake=0.301, H_real=0.874]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [01:33<00:00,  1.60it/s, H_fake=0.272, H_real=0.899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [01:33<00:00,  1.60it/s, H_fake=0.27, H_real=0.898]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [01:35<00:00,  1.58it/s, H_fake=0.256, H_real=0.891]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [01:33<00:00,  1.60it/s, H_fake=0.256, H_real=0.893]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [01:33<00:00,  1.60it/s, H_fake=0.278, H_real=0.881]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [01:34<00:00,  1.59it/s, H_fake=0.308, H_real=0.858]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [01:34<00:00,  1.60it/s, H_fake=0.297, H_real=0.868]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "metadata": {
        "id": "A1S4cpNnE-EG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e76694-f4d5-4bde-83f4-d9001d57af84"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 1, 30, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(\n",
        "        list(gen_Z.parameters()) + list(gen_H.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "-tTHNl6XzHtp",
        "outputId": "71ccf799-cac4-45a8-bb4d-b60359807457"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-d283501ee1ee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer = optim.Adam(\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_Z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_H\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gen_Z' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import optimizer"
      ],
      "metadata": {
        "id": "7i8MKDp5zpT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_checkpoint('genX.pth.tar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "3SJD4Xxs0V6c",
        "outputId": "d71eb33c-7843-4017-e4cc-756a8160ebac"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-19f297b5fe0e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'genX.pth.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: load_checkpoint() missing 3 required positional arguments: 'model', 'optimizer', and 'lr'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of loading the model\n",
        "checkpoint = torch.load('genX.pth.tar')\n",
        "model = UNET  # Initialize your model class\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "Ges6siQCzpR7",
        "outputId": "4ca37f83-1677-4189-bf5e-2f5b5a2782ce"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-e0e6ca5cef85>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'genX.pth.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNET\u001b[0m  \u001b[0;31m# Initialize your model class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Module.load_state_dict() missing 1 required positional argument: 'state_dict'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint['state_dict'].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWyJMrD5zpPX",
        "outputId": "6a941c41-e956-422c-fcad-b8a96f686b60"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['upsample_steps.0.weight', 'upsample_steps.0.bias', 'upsample_steps.1.conv.0.weight', 'upsample_steps.1.conv.1.weight', 'upsample_steps.1.conv.1.bias', 'upsample_steps.1.conv.1.running_mean', 'upsample_steps.1.conv.1.running_var', 'upsample_steps.1.conv.1.num_batches_tracked', 'upsample_steps.1.conv.3.weight', 'upsample_steps.1.conv.4.weight', 'upsample_steps.1.conv.4.bias', 'upsample_steps.1.conv.4.running_mean', 'upsample_steps.1.conv.4.running_var', 'upsample_steps.1.conv.4.num_batches_tracked', 'upsample_steps.2.weight', 'upsample_steps.2.bias', 'upsample_steps.3.conv.0.weight', 'upsample_steps.3.conv.1.weight', 'upsample_steps.3.conv.1.bias', 'upsample_steps.3.conv.1.running_mean', 'upsample_steps.3.conv.1.running_var', 'upsample_steps.3.conv.1.num_batches_tracked', 'upsample_steps.3.conv.3.weight', 'upsample_steps.3.conv.4.weight', 'upsample_steps.3.conv.4.bias', 'upsample_steps.3.conv.4.running_mean', 'upsample_steps.3.conv.4.running_var', 'upsample_steps.3.conv.4.num_batches_tracked', 'upsample_steps.4.weight', 'upsample_steps.4.bias', 'upsample_steps.5.conv.0.weight', 'upsample_steps.5.conv.1.weight', 'upsample_steps.5.conv.1.bias', 'upsample_steps.5.conv.1.running_mean', 'upsample_steps.5.conv.1.running_var', 'upsample_steps.5.conv.1.num_batches_tracked', 'upsample_steps.5.conv.3.weight', 'upsample_steps.5.conv.4.weight', 'upsample_steps.5.conv.4.bias', 'upsample_steps.5.conv.4.running_mean', 'upsample_steps.5.conv.4.running_var', 'upsample_steps.5.conv.4.num_batches_tracked', 'upsample_steps.6.weight', 'upsample_steps.6.bias', 'upsample_steps.7.conv.0.weight', 'upsample_steps.7.conv.1.weight', 'upsample_steps.7.conv.1.bias', 'upsample_steps.7.conv.1.running_mean', 'upsample_steps.7.conv.1.running_var', 'upsample_steps.7.conv.1.num_batches_tracked', 'upsample_steps.7.conv.3.weight', 'upsample_steps.7.conv.4.weight', 'upsample_steps.7.conv.4.bias', 'upsample_steps.7.conv.4.running_mean', 'upsample_steps.7.conv.4.running_var', 'upsample_steps.7.conv.4.num_batches_tracked', 'downsample_steps.0.conv.0.weight', 'downsample_steps.0.conv.1.weight', 'downsample_steps.0.conv.1.bias', 'downsample_steps.0.conv.1.running_mean', 'downsample_steps.0.conv.1.running_var', 'downsample_steps.0.conv.1.num_batches_tracked', 'downsample_steps.0.conv.3.weight', 'downsample_steps.0.conv.4.weight', 'downsample_steps.0.conv.4.bias', 'downsample_steps.0.conv.4.running_mean', 'downsample_steps.0.conv.4.running_var', 'downsample_steps.0.conv.4.num_batches_tracked', 'downsample_steps.1.conv.0.weight', 'downsample_steps.1.conv.1.weight', 'downsample_steps.1.conv.1.bias', 'downsample_steps.1.conv.1.running_mean', 'downsample_steps.1.conv.1.running_var', 'downsample_steps.1.conv.1.num_batches_tracked', 'downsample_steps.1.conv.3.weight', 'downsample_steps.1.conv.4.weight', 'downsample_steps.1.conv.4.bias', 'downsample_steps.1.conv.4.running_mean', 'downsample_steps.1.conv.4.running_var', 'downsample_steps.1.conv.4.num_batches_tracked', 'downsample_steps.2.conv.0.weight', 'downsample_steps.2.conv.1.weight', 'downsample_steps.2.conv.1.bias', 'downsample_steps.2.conv.1.running_mean', 'downsample_steps.2.conv.1.running_var', 'downsample_steps.2.conv.1.num_batches_tracked', 'downsample_steps.2.conv.3.weight', 'downsample_steps.2.conv.4.weight', 'downsample_steps.2.conv.4.bias', 'downsample_steps.2.conv.4.running_mean', 'downsample_steps.2.conv.4.running_var', 'downsample_steps.2.conv.4.num_batches_tracked', 'downsample_steps.3.conv.0.weight', 'downsample_steps.3.conv.1.weight', 'downsample_steps.3.conv.1.bias', 'downsample_steps.3.conv.1.running_mean', 'downsample_steps.3.conv.1.running_var', 'downsample_steps.3.conv.1.num_batches_tracked', 'downsample_steps.3.conv.3.weight', 'downsample_steps.3.conv.4.weight', 'downsample_steps.3.conv.4.bias', 'downsample_steps.3.conv.4.running_mean', 'downsample_steps.3.conv.4.running_var', 'downsample_steps.3.conv.4.num_batches_tracked', 'bottleneck.conv.0.weight', 'bottleneck.conv.1.weight', 'bottleneck.conv.1.bias', 'bottleneck.conv.1.running_mean', 'bottleneck.conv.1.running_var', 'bottleneck.conv.1.num_batches_tracked', 'bottleneck.conv.3.weight', 'bottleneck.conv.4.weight', 'bottleneck.conv.4.bias', 'bottleneck.conv.4.running_mean', 'bottleneck.conv.4.running_var', 'bottleneck.conv.4.num_batches_tracked', 'final_conv.weight', 'final_conv.bias'])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nE28_Wg4zpMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6juH5QBQzpJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VW_VGdB-zpFZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}